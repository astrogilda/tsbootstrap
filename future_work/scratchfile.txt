base classes:
Stationary
moving
NonOverlappingSubseries
Circular


tapered -- block
adaptive -- block
Markov -- [whole] and block
Biascorrected -- block and whole
residual/non-parametric (ar-x, arima, var, sarima) -- block and whole
Sieve (ar-x, arima, var, sarima, garch) -- [block **TO DO*] and whole
Fractional -- whole and block
Distributional -- weibull, gamma, Exponential, gamma, bayesian

#TODO:
Spectral -- needs significant reworking; need to properly install that library
Multi-tapered
HAC -- block and whole

(pair -- same as moving with block_length=2) TODO: test this





# TODO: use TypeVar to allow for different types of data (e.g. numpy arrays, pandas dataframes, lists, etc.)
# TODO: add option for block length to be a fraction of the data length
# TODO: use Type to indicate the type of the data (even classes), instead of directly reference the instance
# TODO: add option for multiprocessing using mp.pool in _iter_test_masks and _generate_samples
# TODO: add an option for VECM (vector error correction model) bootstrap
# TODO: write a data abstraction layer that converts data to a common format (e.g. numpy arrays) and back. also convert 1d to 2d arrays, and check for dimensionality and type consistency and convert if necessary.
# TODO: test vs out-of-bootstrap samples; should we split in the abstract layer itself and only pass the training set to the bootstrap generator?
# TODO: __init__ files for all submodules
# TODO: explain how _iter_test_mask is only kept for backwards compatibility and is not used in the bootstrap generator
# TODO: add option for block_length to be None, in which case it is set to the square root of the data length
# TODO: add option for block_length to be a list of integers, in which case it is used as the block length for each bootstrap sample
# TODO: Hierarchical Archimedean Copula

